{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "_This notebook was put together by [Keneth Garcia](https://stivengarcia7113.wixsite.com/kenethgarcia). Source and license info are on [GitHub](https://github.com/KenethGarcia/GRB_ML)._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# T-distributed Stochastic Neighbor Embedding (t-SNE) in Swift Data\n",
    "The Neil Gehrels Swift Observatory presents analysis results for the Swift/BAT Gamma-Ray Burst (GRBs) on [this website](https://swift.gsfc.nasa.gov/results/batgrbcat/) (open access).\n",
    "\n",
    "As suggested by [Jespersen et al. (2020)](https://ui.adsabs.harvard.edu/abs/2020ApJ...896L..20J/abstract), Swift GRBs can be separated into two groups when t-SNE is performed. In this Jupyter notebook, we replicate this work by adding more recent data and an in-depth analysis of t-SNE performance. Through this document, we are using the _python3_ implementations from the _scripts_ folder. It is necessary to have a _Jupyter Notebook_/_Python 3_ compiler software.\n",
    "\n",
    "First, we need to import the **main.py** file to our notebook (and some packages needed):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from scripts import main\n",
    "import os  # Import os to handle folders and files\n",
    "import numpy as np  # Import numpy module to read tables, manage data, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Then, create a new object from the `main.py` class and, if you need, set the data, table and results folder paths (by default it will be the \"Data\", \"Table\", and \"Results\" folders inside the path containing this notebook):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "object1 = main.SwiftGRBWorker()\n",
    "object1.original_data_path = r'G:\\Mi unidad\\Cursos\\Master_Degree_Project\\GRB_ML\\Data\\Original_Data'  # Change original data path\n",
    "object1.table_path = r'G:\\Mi unidad\\Cursos\\Master_Degree_Project\\GRB_ML\\Tables'  # Change table path\n",
    "object1.results_path = r'G:\\Mi unidad\\Cursos\\Master_Degree_Project\\GRB_ML\\Results'  # Change results path\n",
    "object1.noise_data_path = r'G:\\Mi unidad\\Cursos\\Master_Degree_Project\\GRB_ML\\Data\\Noise_Filtered_Data'\n",
    "object1.noise_images_path = r'G:\\Mi unidad\\Cursos\\Master_Degree_Project\\GRB_ML\\Results\\Noise_Filter_Images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "If you haven't downloaded the data yet, check the _Swift_Data_Download_ notebook.\n",
    "\n",
    "**REMARK:** This notebook uses the results obtained in previous notebooks; before continuing, check at least the _Swift_Data_Download_ and _Data_Preprocessing_ notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Changing the Swift GRB binning\n",
    "By default, this notebook uses the data for 64ms binning in Swift. There are some cases in which we need to use different data resolutions and binning; handling these situations can be solved in this package by managing the _resolution_ and _end_ variables.\n",
    "\n",
    "Through this package, you can change the _resolution_ variable to $2$, $8$, $16$, $64$, and $256$ ms respectively. Additionally, you can set $1$ for 1s binning and change the end variable to \"sn5_10s\" to use data with a signal-to-noise ratio higher than 5 or 10 s binning (these data don't have uniform time spacing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "object1.res = 64  # Resolution for the Light Curve Data in ms, could be 2, 8, 16, 64 (default), 256 and 1 (this last in s)\n",
    "# object1.end = \"sn5_10s\"  # Uncomment this line if you need to use signal-to-noise higher than 5 or 10s binning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "It is advisable not to change both variables at the same time; this could cause unknown bugs when running package routines and sub-routines. Additionally, you will need the data downloaded for the selected binning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# t-SNE in Swift Data\n",
    "t-Distributed Stochastic Neighbor Embedding (or t-SNE) is a popular non-linear dimensionality reduction technique used for visualizing high dimensional data sets. After pre-processing Swift data in the $x_i$ vectors with Fourier Amplitudes, we want to perform this method by taking so much care when we read the results. Why? The t-SNE algorithm doesn’t always produce similar output on successive runs, and it depends on some hyperparameters related to the optimization process.\n",
    "\n",
    "In this study, the most relevant hyperparameters on the cost function are (following the scikit-Learn and open-TSNE packages documentation):\n",
    "* __Perplexity__: The perplexity is related to the number of nearest neighbors that is used in other manifold learning algorithms. Larger datasets usually require a larger perplexity. Note that perplexity linearly impacts runtime i.e. higher values of perplexity will incur longer execution time.\n",
    "* __learning_rate__: The learning rate controls the step size of the gradient updates. If the learning rate is too high, the data may look like a ‘ball’ with any point approximately equidistant from its nearest neighbours. If the learning rate is too low, most points may look compressed in a dense cloud with few outliers.\n",
    "* __metric__: The metric to use when calculating distance between instances in a feature array.\n",
    "\n",
    "## t-SNE convergency\n",
    "First of all, we want to see how t-SNE converges in the pre-processed data. To do this, we use the `convergence_animation` function, it is based in [tsne_animate](https://github.com/sophronesis/tsne_animate) package from GitHub in its `tsne_animation` function. But, before we need to load the pre-processing data saved:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1318 GRBs loaded: ['GRB200829A' 'GRB200819A' 'GRB200809B' ... 'GRB041220' 'GRB041219C'\n",
      " 'GRB041217']\n"
     ]
    }
   ],
   "source": [
    "data_loaded = np.load(os.path.join(object1.results_path, f\"DFT_Preprocessed_data_{object1.end}.npz\"))\n",
    "GRB_names, features = data_loaded['GRB_Names'], data_loaded['Data']\n",
    "print(f\"There are {len(GRB_names)} GRBs loaded: {GRB_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now, we will index GRBs durations (using the `durations_checker` instance) to see the results dependence with this feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding Durations: 100%|██████████| 1318/1318 [00:09<00:00, 145.33GRB/s]\n"
     ]
    }
   ],
   "source": [
    "durations_data_array = object1.durations_checker(GRB_names, t=90)  # Check for name, t_start, and t_end\n",
    "start_times, end_times = durations_data_array[:, :, 1].astype(float), durations_data_array[:, :, 2].astype(float)\n",
    "durations = np.reshape(end_times - start_times, len(durations_data_array))  # T_90 is equal to t_end - t_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Then we set the standard _perplexity_ value (30) from [Jespersen et al. (2020)](https://ui.adsabs.harvard.edu/abs/2020ApJ...896L..20J/abstract), set auto _learning rate_ in scikit-Learn t-SNE implementation, and perform the animation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "file_name = os.path.join('README_files', 'convergence_animation_pp_30.gif')\n",
    "object1.convergence_animation(features, filename=file_name, perplexity=30, duration_s=durations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
