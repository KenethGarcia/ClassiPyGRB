{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "_This notebook was put together by [Keneth Garcia](https://stivengarcia7113.wixsite.com/kenethgarcia). Source and license info are on [GitHub](https://github.com/KenethGarcia/GRB_ML)._"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Topic of Current Interest: t-SNE in Swift Data\n",
    "The Neil Gehrels Swift Observatory presents analysis results for the Swift/BAT Gamma-Ray Burst (GRBs) on [this website](https://swift.gsfc.nasa.gov/results/batgrbcat/) (open access).\n",
    "\n",
    "As suggested by [Jespersen et al. (2020)](https://ui.adsabs.harvard.edu/abs/2020ApJ...896L..20J/abstract), Swift GRBs can be separated into two groups when t-SNE is performed. In this Jupyter notebook, we replicate this work by adding more recent data and an in-depth analysis of other preprocessed subsets (i.e., noise filtered data). Through this document, we are using the _python3_ implementations from the _scripts_ folder. It is necessary to have a _Jupyter Notebook_/_Python 3_ compiler software.\n",
    "\n",
    "First, we need to import the **main.py** file to our notebook (and some packages needed):"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from scripts import main\n",
    "import os  # Import os to handle folders and files\n",
    "import numpy as np  # Import numpy module to read tables, manage data, etc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then, create a new object from the `main.py` class and, if you need, set the data, table and results folder paths (by default it will be the \"Data\", \"Table\", and \"Results\" folders inside the path containing this notebook):"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "object1 = main.SwiftGRBWorker()\n",
    "object1.original_data_path = r'G:\\Mi unidad\\Cursos\\Master_Degree_Project\\GRB_ML\\Data\\Original_Data'  # Change original data path\n",
    "object1.table_path = r'G:\\Mi unidad\\Cursos\\Master_Degree_Project\\GRB_ML\\Tables'  # Change table path\n",
    "object1.results_path = r'G:\\Mi unidad\\Cursos\\Master_Degree_Project\\GRB_ML\\Results'  # Change results path\n",
    "object1.noise_data_path = r'G:\\Mi unidad\\Cursos\\Master_Degree_Project\\GRB_ML\\Data\\Noise_Filtered_Data'\n",
    "object1.noise_images_path = r'G:\\Mi unidad\\Cursos\\Master_Degree_Project\\GRB_ML\\Results\\Noise_Filter_Images'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "If you haven't downloaded the data yet, check the _Swift_Data_Download_ notebook.\n",
    "\n",
    "**REMARK:** This notebook uses the results obtained in previous notebooks; before continuing, check at least the _Swift_Data_Download_ and _Data_Preprocessing_ notebooks."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Changing the Swift GRB binning\n",
    "By default, this notebook uses the data for 64ms binning in Swift. There are some cases in which we need to use different data resolutions and binning; handling these situations can be solved in this package by managing the _resolution_ and _end_ variables.\n",
    "\n",
    "Through this package, you can change the _resolution_ variable to $2$, $8$, $16$, $64$, and $256$ ms respectively. Additionally, you can set $1$ for 1s binning and change the end variable to \"sn5_10s\" to use data with a signal-to-noise ratio higher than 5 or 10 s binning (these data don't have uniform time spacing)."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "object1.res = 64  # Resolution for the Light Curve Data in ms, could be 2, 8, 16, 64 (default), 256 and 1 (this last in s)\n",
    "# object1.end = \"sn5_10s\"  # Uncomment this line if you need to use signal-to-noise higher than 5 or 10s binning"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It is advisable not to change both variables at the same time; this could cause unknown bugs when running package routines and sub-routines. Additionally, you will need the data downloaded for the selected binning."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Relevant topics\n",
    "\n",
    "In this study, we are interested in seeing patterns in tSNE embeddings. Then we searched different relevant subsets of GRBs (and topics) motivated by the tSNE convergence variation explained in the _t-SNE_Introduction_. In particular, we try to separate two groups (usually named short and long) by their underlying physical process. The following subsections review the main findings made in this task.\n",
    "\n",
    "Before continue, let's define the perplexity values to perform t-SNE animations:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pp = np.array([4, 5, 6, 7, 8, 9, 10, 15, 17, 20, 25, 30, 50, 75, 100, 150, 200, 250, 300, 350, 400, 450])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In addition, as a reference, add the animation obtained in _t-SNE_Introduction_ notebook:\n",
    "\n",
    "![](Animations/perplexity_animation.gif)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessed data without DFT\n",
    "\n",
    "As suggested by Jespersen: _\"It should be noted that the DFT is not necessarily an optimal preprocessing solution for separating GRBs (...)\"_, motivated by this fact, the easiest thing is to think about not using the DFT at all. The t-SNE results with preprocessed data without DFT follows:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "non_DFT_data_loaded = np.load(os.path.join(object1.results_path, f\"non_DFT_Preprocessed_data_{object1.end}.npz\"))\n",
    "non_DFT_GRB_names, non_DFT_features = non_DFT_data_loaded['GRB_Names'], non_DFT_data_loaded['Data']\n",
    "durations_data_array = object1.durations_checker(non_DFT_GRB_names, t=90)  # Check for name, t_start, and t_end\n",
    "start_times, end_times = durations_data_array[:, :, 1].astype(float), durations_data_array[:, :, 2].astype(float)\n",
    "non_DFT_durations = np.reshape(end_times - start_times, len(durations_data_array))  # T_90 is equal to t_end - t_start\n",
    "file_name = os.path.join('Animations', 'perplexity_animation_non_DFT.gif')\n",
    "object1.tsne_animation(non_DFT_features, iterable='perplexity', perplexity=pp, library='sklearn', duration_s=non_DFT_durations, filename=file_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](Animations/perplexity_animation_non_DFT.gif)\n",
    "\n",
    "In this case, there are two relevant remarks:\n",
    "1. The visualization map is more cloudy than the DFT pre-processed case.\n",
    "2. Mainly at perplexity < 20, there are two clear subgroups with different mean durations. More important, these subgroups don't need any customized optimization parameters to be visible (specific learning rate, iteration number, etc.)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Removing suspicious GRBs\n",
    "In the [lists of GRBs with special comments](https://swift.gsfc.nasa.gov/results/batgrbcat/summary_cflux/summary_GRBlist), there is some info about failed or partially failed GRB measuring. These GRBs can distract the tSNE algorithm, and fill the spaces between defined groups, broking their general structure.\n",
    "\n",
    "The GRBs removed are part of the lists:\n",
    "1. `GRBlist_not_enough_evt_data.txt`:  The event data are only available for part of the burst duration.\n",
    "2. `GRBlist_tentative_detection_with_note.txt` and `GRBlist_tentative_detection.txt`: GRBs with tentative detection.\n",
    "3. `Obvious_data_gap.txt`: Obvious data gap within the burst duration.\n",
    "\n",
    "You can download these tables using the `summary_tables_download` instance:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tables = ('GRBlist_not_enough_evt_data.txt', 'GRBlist_tentative_detection_with_note.txt', 'GRBlist_tentative_detection.txt', 'Obvious_data_gap.txt')\n",
    "[object1.summary_tables_download(name=name, other=True) for name in tables]  # Un-comment this line to download tables"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Read the tables and index the GRB names:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tables_path = object1.table_path\n",
    "excluded_names = np.array([])\n",
    "for table in tables:\n",
    "    names_i = np.genfromtxt(os.path.join(tables_path, table), usecols=(0, 1), dtype=str)[:, 0]\n",
    "    excluded_names = np.append(excluded_names, names_i)\n",
    "excluded_names = np.unique(excluded_names)\n",
    "print(f\"There are {len(excluded_names)} GRBs to be excluded\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Read the preprocessed data with DFT and index their durations:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding Durations: 100%|██████████| 1318/1318 [00:09<00:00, 138.43GRB/s]\n"
     ]
    }
   ],
   "source": [
    "data_loaded = np.load(os.path.join(object1.results_path, f\"DFT_Preprocessed_data_{object1.end}.npz\"))\n",
    "GRB_names, features = data_loaded['GRB_Names'], data_loaded['Data']\n",
    "durations_data_array = object1.durations_checker(GRB_names, t=90)  # Check for name, t_start, and t_end\n",
    "start_times, end_times = durations_data_array[:, :, 1].astype(float), durations_data_array[:, :, 2].astype(float)\n",
    "durations = np.reshape(end_times - start_times, len(durations_data_array))  # T_90 is equal to t_end - t_start"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Remove elements from the original GRB names and features array:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "non_match = np.where(np.isin(GRB_names, excluded_names, invert=True))[0]\n",
    "GRB_names_excluded = GRB_names[non_match]\n",
    "features_excluded = features[non_match]\n",
    "durations_excluded = durations[non_match]\n",
    "print(f\"Now there are {len(GRB_names_excluded)} GRBs to perform tSNE\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "With these GRB, now the tSNE embedding follows:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_name = os.path.join('README_files', 'perplexity_animation_2.gif')\n",
    "object1.tsne_animation(features_excluded, iterable='perplexity', perplexity=pp, library='sklearn', duration_s=durations_excluded, filename=file_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](Animations/perplexity_animation_2.gif)\n",
    "\n",
    "As you can see, without these suspicious GRBs, the two subgroups are evident at perplexity < 10, while there aren't so many changes in the t-SNE convergence compared with reference animation.\n",
    "\n",
    "Now, taking the pre-processing data without DFT and removing the same suspicious GRBs:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "non_match_2 = np.where(np.isin(non_DFT_GRB_names, excluded_names, invert=True))[0]\n",
    "non_DFT_GRB_names_excluded = non_DFT_GRB_names[non_match_2]\n",
    "non_DFT_features_excluded = non_DFT_features[non_match_2]\n",
    "non_DFT_durations_excluded = non_DFT_durations[non_match_2]\n",
    "print(f\"Now there are {len(non_DFT_GRB_names_excluded)} GRBs to perform tSNE\")\n",
    "file_name = os.path.join('Animations', 'perplexity_animation_3.gif')\n",
    "object1.tsne_animation(non_DFT_features_excluded, iterable='perplexity', perplexity=pp, library='sklearn', duration_s=non_DFT_durations_excluded, filename=file_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](Animations/perplexity_animation_3.gif)\n",
    "\n",
    "At low perplexity values, it seems that there is a small grouping of very long GRBs."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Noise Reduction\n",
    "Another alternative to improve t-SNE results is to reduce the data noise. Swift data are particularly noisy, and taking more cleaned light curves for t-SNE can refine its results.\n",
    "\n",
    "We use the non-parametric noise reduction technique results obtained from the FABADA package (see _Noise_Reduction_ notebook for further details). First, we need to load the features and durations:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fabada_data_loaded = np.load(os.path.join(object1.results_path, f\"DFT_Noise_Filtered_data_{object1.end}.npz\"))\n",
    "fabada_GRB_names, fabada_features = fabada_data_loaded['GRB_Names'], fabada_data_loaded['Data']\n",
    "durations_data_array = object1.durations_checker(GRB_names, t=90)  # Check for name, t_start, and t_end\n",
    "start_times, end_times = durations_data_array[:, :, 1].astype(float), durations_data_array[:, :, 2].astype(float)\n",
    "fabada_durations = np.reshape(end_times - start_times, len(durations_data_array))  # T_90 is equal to t_end - t_start"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The embedding follows:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_name = os.path.join('README_files', 'perplexity_animation_noise_filtered.gif')\n",
    "object1.tsne_animation(fabada_features, iterable='perplexity', perplexity=pp, library='sklearn', duration_s=fabada_durations, filename=file_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "![](Animations/perplexity_animation_noise_filtered.gif)\n",
    "\n",
    "In this case, there are two relevant remarks:\n",
    "1. The visualization map changes this form with the DFT pre-processed case. It is more curved, but the main idea is the same: duration and GRB map position are correlated.\n",
    "2. For all perplexity < 50, there are two clear subgroups with different mean durations. Furthermore, this is the most perceptible case: these subgroups are wholly separate. And again, these subgroups don't need any customized optimization parameters to be visible (specific learning rate, iteration number, etc.) and uses the DFT approach.\n",
    "As expected, when we highly reduce noise in the whole dataset, the t-SNE visualization maps improve.\n",
    "\n",
    "Now, for the pre-processed data without DFT we get:\n",
    "\n",
    "![](Animations/perplexity_animation_noise_filtered_2.gif)\n",
    "\n",
    "The visualization maps follow the same structure as the DFT case, but there aren't any subgroups remarked (except for perplexity = 300).\n",
    "\n",
    "At this point, the most important result is: **There are two subgroups separated in the visualization maps**. The reader can check the GRBs involved in each cloud and analyze them.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using data with a high Signal-to-noise ratio\n",
    "Another approach to handle the noise problem is to use high signal-to-noise ratio data from Swift. In particular, there is one file named \"sn5_10s_lc_ascii.dat\" for each GRB in Swift Database. In this file, we can find the 10 seconds average binning light curve. In most cases, the GRB structure is better than 64ms binning. Then we can perform t-SNE on this data to check what happens when we use fewer points but more consistency.\n",
    "\n",
    "First, as we pointed out in _Data_Interpolating_ notebook: we need to handle with time basis to pre-process data (the data doesn't have uniform time spacing). To solve this problem, we interpolate between data points using a fixed time step and pre-process these interpolate data normally.\n",
    "\n",
    "Now, to perform t-SNE, we need to read the pre-processed data:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "interpolate_data_loaded = np.load(os.path.join(object1.results_path, f\"DFT_Interpolated_data_{object1.end}\"))\n",
    "interpolate_GRB_names, interpolate_features = interpolate_data_loaded['GRB_Names'], interpolate_data_loaded['Data']\n",
    "durations_data_array = object1.durations_checker(GRB_names, t=90)  # Check for name, t_start, and t_end\n",
    "start_times, end_times = durations_data_array[:, :, 1].astype(float), durations_data_array[:, :, 2].astype(float)\n",
    "interpolate_durations = np.reshape(end_times - start_times, len(durations_data_array))  # T_90 is equal to t_end - t_start"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "And to perform the embedding:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_name = os.path.join('Animations', 'perplexity_animation_interpolated.gif')\n",
    "object1.tsne_animation(interpolate_features, iterable='perplexity', perplexity=pp, library='sklearn', duration_s=interpolate_durations, filename=file_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}